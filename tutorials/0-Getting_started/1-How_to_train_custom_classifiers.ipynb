{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train a custom classifier\n",
    "\n",
    "This tutorial provides step-by-step instructions for building a new classifier on a personalized set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir('local'):\n",
    "    os.mkdir('local')\n",
    "if not os.path.isdir('local/custom_classifier'):\n",
    "    os.mkdir('local/custom_classifier')\n",
    "    \n",
    "os.chdir('local/custom_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom training dataset\n",
    "First, we need to build a custom training dataset, for instance by extending the Integrated Dataset that comes with Rhapsody. \n",
    "\n",
    "New feature arrays must have the same length as those already in the Integrated Dataset. Information about size and composition of the default training dataset is stored in the installation settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rhapsody as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> rhapsody_local_folder   : /home/luca/rhapsody\n",
      "@> EVmutation_local_folder : /home/luca/rhapsody/EVmutation_mutation_effects\n",
      "@> full classifier         : /home/luca/rhapsody/default_classifiers-sklearn_v0.21.3/full/trained_classifier.pkl\n",
      "@> reduced classifier      : /home/luca/rhapsody/default_classifiers-sklearn_v0.21.3/reduced/trained_classifier.pkl\n",
      "@> EVmut classifier        : /home/luca/rhapsody/default_classifiers-sklearn_v0.21.3/EVmut/trained_classifier.pkl\n",
      "@> training dataset size   : 20361\n",
      "@> EVmutation_metrics      : <computed>\n"
     ]
    }
   ],
   "source": [
    "settings = rd.getSettings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20361"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings['rhapsody_training_dataset']['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SAV_coords',\n",
       " 'Uniprot2PDB',\n",
       " 'PDB_length',\n",
       " 'true_label',\n",
       " 'ANM_MSF-chain',\n",
       " 'ANM_MSF-reduced',\n",
       " 'ANM_MSF-sliced',\n",
       " 'ANM_effectiveness-chain',\n",
       " 'ANM_effectiveness-reduced',\n",
       " 'ANM_effectiveness-sliced',\n",
       " 'ANM_sensitivity-chain',\n",
       " 'ANM_sensitivity-reduced',\n",
       " 'ANM_sensitivity-sliced',\n",
       " 'BLOSUM',\n",
       " 'Delta_PSIC',\n",
       " 'Delta_SASA',\n",
       " 'EVmut-DeltaE_epist',\n",
       " 'EVmut-DeltaE_indep',\n",
       " 'EVmut-mut_aa_freq',\n",
       " 'EVmut-wt_aa_cons',\n",
       " 'GNM_MSF-chain',\n",
       " 'GNM_MSF-reduced',\n",
       " 'GNM_MSF-sliced',\n",
       " 'GNM_effectiveness-chain',\n",
       " 'GNM_effectiveness-reduced',\n",
       " 'GNM_effectiveness-sliced',\n",
       " 'GNM_sensitivity-chain',\n",
       " 'GNM_sensitivity-reduced',\n",
       " 'GNM_sensitivity-sliced',\n",
       " 'SASA',\n",
       " 'SASA_in_complex',\n",
       " 'entropy',\n",
       " 'ranked_MI',\n",
       " 'stiffness-chain',\n",
       " 'stiffness-reduced',\n",
       " 'stiffness-sliced',\n",
       " 'wt_PSIC')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings['rhapsody_training_dataset']['fields']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's add a new field `PDB_length`, extracted from the Integrated Dataset, to the \"full\" Rhapsody training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ds = rd.getDefaultTrainingDataset()\n",
    "array = default_ds['PDB_length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array already has the correct length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20361"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call this extra field `'new_feature'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([('A0FGR8 210 C S', 0, -2.053, 0.305, 13., 1.6369812 , 0.47203878, 0.48780644, 10.934773 , 1.9736528, 0.7888889, -1., 455.),\n",
       "           ('A0FGR8 638 S G', 0, -2.261, 1.017, 70., 1.1408623 , 0.6298156 , 0.44004798, 11.919116 ,       nan,       nan,  0., 455.),\n",
       "           ('A1Z1Q3 58 T I', 0, -1.815, 1.578, 85., 4.432677  , 0.0067604 , 0.6147862 , 10.329021 ,       nan,       nan, -1., 221.),\n",
       "           ...,\n",
       "           ('Q9Y6X9 283 R H', 0, -1.281, 2.726, 30., 0.474798  , 0.48984432, 0.19532807, 13.609769 ,       nan,       nan,  0., 536.),\n",
       "           ('Q9Y6X9 466 D H', 0, -1.261, 3.143, 71., 0.46281278, 0.45384642, 0.16229136, 13.8006115,       nan,       nan, -1., 536.),\n",
       "           ('Q9Y6X9 87 S L', 1, -1.239, 1.896, 17., 0.4945855 , 0.57216614, 0.23604834, 13.548991 , 1.1867005, 0.5555556, -2., 536.)],\n",
       "          dtype=[('SAV_coords', '<U50'), ('true_label', '<i2'), ('wt_PSIC', '<f4'), ('Delta_PSIC', '<f4'), ('SASA', '<f4'), ('ANM_MSF-chain', '<f4'), ('ANM_effectiveness-chain', '<f4'), ('ANM_sensitivity-chain', '<f4'), ('stiffness-chain', '<f4'), ('entropy', '<f4'), ('ranked_MI', '<f4'), ('BLOSUM', '<f4'), ('new_feature', '<f4')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training_dataset = rd.extendDefaultTrainingDataset('new_feature', array)\n",
    "new_training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple new features can be added at once by providing a list of arrays:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rd.extendDefaultTrainingDataset(['new_feature_1', 'new_feature_2', ...], [array1, array2, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A completely different training dataset can also be built from scratch, by creating a NumPy structured array, containing the two mandatory fields `SAV_coords` and `true_label`.\n",
    "\n",
    "Finally, let's train the new custom classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> 3918 out of 20361 cases ignored with missing features.\n",
      "@> CV iteration # 1:   AUROC = 0.871   AUPRC = 0.932   OOB score = 0.820\n",
      "@> CV iteration # 2:   AUROC = 0.874   AUPRC = 0.934   OOB score = 0.818\n",
      "@> CV iteration # 3:   AUROC = 0.866   AUPRC = 0.925   OOB score = 0.821\n",
      "@> CV iteration # 4:   AUROC = 0.878   AUPRC = 0.934   OOB score = 0.819\n",
      "@> CV iteration # 5:   AUROC = 0.872   AUPRC = 0.935   OOB score = 0.821\n",
      "@> CV iteration # 6:   AUROC = 0.877   AUPRC = 0.937   OOB score = 0.820\n",
      "@> CV iteration # 7:   AUROC = 0.871   AUPRC = 0.931   OOB score = 0.820\n",
      "@> CV iteration # 8:   AUROC = 0.871   AUPRC = 0.933   OOB score = 0.821\n",
      "@> CV iteration # 9:   AUROC = 0.862   AUPRC = 0.923   OOB score = 0.820\n",
      "@> CV iteration #10:   AUROC = 0.879   AUPRC = 0.934   OOB score = 0.819\n",
      "@> ------------------------------------------------------------\n",
      "@> Cross-validation summary:\n",
      "@> training dataset size:   16443\n",
      "@> fraction of positives:   0.690\n",
      "@> mean AUROC:              0.872 +/- 0.005\n",
      "@> mean AUPRC:              0.932 +/- 0.004\n",
      "@> mean OOB score:          0.820 +/- 0.001\n",
      "@> optimal cutoff*:         0.711 +/- 0.034\n",
      "@> (* argmax of Youden's index)\n",
      "@> feature importances:\n",
      "@>                 wt_PSIC: 0.143\n",
      "@>              Delta_PSIC: 0.189\n",
      "@>                    SASA: 0.068\n",
      "@>           ANM_MSF-chain: 0.074\n",
      "@> ANM_effectiveness-chain: 0.078\n",
      "@>   ANM_sensitivity-chain: 0.071\n",
      "@>         stiffness-chain: 0.080\n",
      "@>                 entropy: 0.099\n",
      "@>               ranked_MI: 0.068\n",
      "@>                  BLOSUM: 0.047\n",
      "@>             new_feature: 0.084\n",
      "@> ------------------------------------------------------------\n",
      "@> Predictions distribution saved to predictions_distribution.png\n",
      "@> Pathogenicity plot saved to pathogenicity_prob.png\n",
      "@> ROC plot saved to ROC.png\n",
      "@> ------------------------------------------------------------\n",
      "@> Classifier training summary:\n",
      "@> mean OOB score:          0.821\n",
      "@> feature importances:\n",
      "@>                 wt_PSIC: 0.140\n",
      "@>              Delta_PSIC: 0.191\n",
      "@>                    SASA: 0.068\n",
      "@>           ANM_MSF-chain: 0.074\n",
      "@> ANM_effectiveness-chain: 0.078\n",
      "@>   ANM_sensitivity-chain: 0.071\n",
      "@>         stiffness-chain: 0.080\n",
      "@>                 entropy: 0.098\n",
      "@>               ranked_MI: 0.068\n",
      "@>                  BLOSUM: 0.048\n",
      "@>             new_feature: 0.084\n",
      "@> ------------------------------------------------------------\n",
      "@> Feat. importance plot saved to feat_importances.png\n"
     ]
    }
   ],
   "source": [
    "new_clsf_info = rd.trainRFclassifier(new_training_dataset, pickle_name='custom_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** Note that, although its introduction yields an increased accuracy, the PDB size is not a good feature and probably reflects an intrinsic bias of the training dataset (more deleterious SAVs have been reported for  proteins of larger size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new custom classifier accuracy\n",
    "new_clsf_info['CV summary']['mean AUROC']\n",
    "del new_clsf_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "full_clsf_fname = rd.getDefaultClassifiers()['full']\n",
    "full_clsf = pickle.load(open(full_clsf_fname, 'rb'))\n",
    "\n",
    "# \"full\" Rhapsody classifier accuracy\n",
    "full_clsf['CV summary']['mean AUROC']\n",
    "del full_clsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting predictions based on custom classifier\n",
    "Here we show how to obtain pathogenicity predictions for a small set of 5 Single Amino acid Variants, using our new custom classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_SAVs = [\n",
    "    'O00294 496 A T',  # know neutral SAV used for training\n",
    "    'O00238 31 R H',   # SAV with no PDB structure\n",
    "    'P01112 58 T R',   # unknown SAV\n",
    "    'P01112 30 D E',   # unknown SAV\n",
    "    'P01112 170 K I',  # unknown SAV with no Pfam domain\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot simply use the main interface `rhapsody()`, because the new feature cannot be computed automatically by Rhapsody:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This will cause an error\n",
    "rh = rd.rhapsody(test_SAVs, main_classifier='custom_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Rhapsody` class contains all the necessary functionalities for getting custom predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> Submitting query to PolyPhen-2...\n",
      "@> Query to PolyPhen-2 started in 9.9s.\n",
      "@> PolyPhen-2 is running...\n",
      "@> Query to PolyPhen-2 completed in 9.7s.\n",
      "@> PolyPhen-2's output parsed.\n"
     ]
    }
   ],
   "source": [
    "# initialize a new instance by importing SAVs and querying PolyPhen-2 directly\n",
    "rh = rd.Rhapsody(query=test_SAVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import new precomputed features\n",
    "features_dict = {\n",
    "    'new_feature': [224,   0, 168, 168, 171]\n",
    "}\n",
    "rh.importPrecomputedExtraFeatures(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> Imported feature set:\n",
      "@>    'wt_PSIC' \n",
      "@>    'Delta_PSIC' \n",
      "@>    'SASA' \n",
      "@>    'ANM_MSF-chain' \n",
      "@>    'ANM_effectiveness-chain' \n",
      "@>    'ANM_sensitivity-chain' \n",
      "@>    'stiffness-chain' \n",
      "@>    'entropy' \n",
      "@>    'ranked_MI' \n",
      "@>    'BLOSUM' \n",
      "@>    'new_feature' \n"
     ]
    }
   ],
   "source": [
    "# import the classifier that will be used for predictions\n",
    "rh.importClassifiers('custom_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@> Sequence-conservation features have been retrieved from PolyPhen-2's output.\n",
      "@> Mapping SAVs to PDB structures...\n",
      "Mapping SAV 'O00238 31 R H' to PDB:   0%|          | 0/5 [00:00<?]@> WARNING Unable to recover pickle: Pickle UniprotMap-O00238.pkl was too old and was ignored.\n",
      "@> PDB file is found in the local folder (/home/luca/.../3mdy.pdb.gz).\n",
      "@> 858 atoms and 1 coordinate set(s) were parsed in 0.06s.\n",
      "Mapping SAV 'O00294 496 A T' to PDB:  20%|██        | 1/5 [00:01<00:05]@> Pickle 'UniprotMap-O00238.pkl' saved.\n",
      "@> WARNING Unable to recover pickle: Pickle UniprotMap-O00294.pkl was too old and was ignored.\n",
      "@> PDB file is found in the local folder (/home/luca/.../2fim.pdb.gz).\n",
      "@> 456 atoms and 1 coordinate set(s) were parsed in 0.06s.\n",
      "@> PDB file is found in the local folder (/home/luca/.../3c5n.pdb.gz).\n",
      "@> 454 atoms and 1 coordinate set(s) were parsed in 0.17s.\n",
      "@> Chain A in 2FIM was aligned in 0.1s.\n",
      "Mapping SAV 'P01112 58 T R' to PDB:  40%|████      | 2/5 [00:02<00:03] @> Pickle 'UniprotMap-O00294.pkl' saved.\n",
      "@> Pickle 'UniprotMap-P01112.pkl' recovered.\n",
      "Mapping SAV 'P01112 170 K I' to PDB: 100%|██████████| 5/5 [00:02<00:00]\n",
      "@> Pickle 'UniprotMap-P01112.pkl' saved.\n",
      "@> 4 out of 5 SAVs have been mapped to PDB in 2.6s.\n",
      "@> Computing structural and dynamical features from PDB structures...\n",
      "Analizing mutation site 1AA9:A 170:   0%|          | 0/5 [00:00<?]@> Pickle 'PDBfeatures-1AA9.pkl' recovered.\n",
      "Analizing mutation site 2FIM:A 443:   0%|          | 0/5 [00:00<?]@> Pickle 'PDBfeatures-1AA9.pkl' saved.\n",
      "@> WARNING Unable to recover pickle: Pickle was too old and was ignored.\n",
      "@> PDB file is found in the local folder (/home/luca/.../2fim.pdb.gz).\n",
      "@> 3841 atoms and 1 coordinate set(s) were parsed in 0.06s.\n",
      "@> Running DSSP...\n",
      "@> DSSP finished in 1.4s.\n",
      "@> Kirchhoff was built in 0.01s.\n",
      "@> 223 modes were calculated in 0.61s.\n",
      "@> Hessian was built in 0.18s.\n",
      "@> 666 modes were calculated in 0.11s.\n",
      "@> Calculating covariance matrix\n",
      "@> Covariance matrix calculated in 0.0s.\n",
      "@> Calculating perturbation response\n",
      "@> Perturbation response matrix calculated in 0.0s.\n",
      "@> Perturbation response scanning completed in 0.1s.\n",
      "@> Calculating stiffness matrix.\n",
      "@> Stiffness matrix calculated in 0.24s.\n",
      "@> The range of effective force constant is: 4.581280954242648 to 26.124107763482908.\n",
      "Analizing mutation site 4Q21:A 58:  60%|██████    | 3/5 [00:03<00:02] @> Pickle 'PDBfeatures-2FIM.pkl' saved.\n",
      "@> Pickle 'PDBfeatures-4Q21.pkl' recovered.\n",
      "Analizing mutation site 4Q21:A 30:  60%|██████    | 3/5 [00:03<00:02]@> Pickle 'PDBfeatures-4Q21.pkl' saved.\n",
      "Analizing mutation site 4Q21:A 30: 100%|██████████| 5/5 [00:03<00:00]\n",
      "@> PDB features have been computed in 3.1s.\n",
      "@> Computing sequence properties from Pfam domains...\n",
      "Mapping SAV 'O00238 31 R H' to Pfam:   0%|          | 0/5 [00:00<?]@> Pickle 'UniprotMap-O00238.pkl' recovered.\n",
      "@> Retrieving Pfam search results: https://pfam.xfam.org/protein/O00238?output=xml\n",
      "@> Pfam search completed in 1.44s.\n",
      "@> Query 'O00238' matched 3 Pfam families.\n",
      "@> Processing PF01064...\n",
      "@> Pfam MSA for PF01064 is written as PF01064_full.sth.\n",
      "@> 1768 sequence(s) with 359 residues were parsed in 0.03s.\n",
      "@> Number of columns in MSA reduced to 77.\n",
      "@> Row occupancy refinement reduced number of rows from 1768 to 1728 in 0.01s.\n",
      "@> Sequence identity refinement reduced number of rows from 1728 to 668 in 0.16s.\n",
      "@> Mutual information matrix was calculated in 0.02s.\n",
      "Mapping SAV 'O00294 496 A T' to Pfam:  20%|██        | 1/5 [00:05<00:23]@> Pickle 'UniprotMap-O00238.pkl' saved.\n",
      "@> Pickle 'UniprotMap-O00294.pkl' recovered.\n",
      "@> Retrieving Pfam search results: https://pfam.xfam.org/protein/O00294?output=xml\n",
      "@> Pfam search completed in 1.07s.\n",
      "@> Query 'O00294' matched 1 Pfam families.\n",
      "@> Processing PF01167...\n",
      "@> Pfam MSA for PF01167 is written as PF01167_full.sth.\n",
      "@> 2789 sequence(s) with 1659 residues were parsed in 0.02s.\n",
      "@> Number of columns in MSA reduced to 241.\n",
      "@> Row occupancy refinement reduced number of rows from 2789 to 2108 in 0.00s.\n",
      "@> Sequence identity refinement reduced number of rows from 2108 to 1102 in 1.07s.\n",
      "@> Mutual information matrix was calculated in 0.24s.\n",
      "Mapping SAV 'P01112 58 T R' to Pfam:  40%|████      | 2/5 [00:14<00:20] @> Pickle 'UniprotMap-O00294.pkl' saved.\n",
      "@> Pickle 'UniprotMap-P01112.pkl' recovered.\n",
      "Mapping SAV 'P01112 170 K I' to Pfam:  40%|████      | 2/5 [00:14<00:20]@> WARNING Unable to compute Pfam features: No Pfam domain for resid 170.\n",
      "@> Pickle 'UniprotMap-P01112.pkl' saved.\n",
      "Mapping SAV 'P01112 170 K I' to Pfam: 100%|██████████| 5/5 [00:14<00:00]\n",
      "@> SAVs have been mapped on Pfam domains and sequence properties have been computed in 15.0s.\n",
      "@> Random Forest classifier imported in 12.6s.\n",
      "@> 3 predictions computed in 0.8s.\n",
      "@> Recovering EVmutation data...\n",
      "@> EVmutation scores recovered in 0.1s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([('O00294 496 A T', 'known_neu', 0.07533333, 0.02985149, 'neutral', 0.351, 'neutral', -3.1479, 'neutral'),\n",
       "       ('O00238 31 R H', 'new',        nan,        nan, '?', 0.219, 'neutral', -2.4718, 'neutral'),\n",
       "       ('P01112 58 T R', 'new', 0.9486667 , 0.9037717 , 'deleterious', 1.   , 'deleterious', -9.7604, 'deleterious'),\n",
       "       ('P01112 30 D E', 'new', 0.126     , 0.04657676, 'neutral', 0.001, 'neutral',  0.2196, 'neutral'),\n",
       "       ('P01112 170 K I', 'new',        nan,        nan, '?', 0.   , 'neutral',     nan, '?')],\n",
       "      dtype=[('SAV coords', '<U50'), ('training info', '<U12'), ('score', '<f4'), ('path. prob.', '<f4'), ('path. class', '<U12'), ('PolyPhen-2 score', '<f4'), ('PolyPhen-2 path. class', '<U12'), ('EVmutation score', '<f4'), ('EVmutation path. class', '<U12')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh.getPredictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
